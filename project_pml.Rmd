---
title: "Practical Machine Learning Course Project"
output: 
    html_document:
        theme: cerulean
date: '2015-02-22'
---

##Executive Summary
Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, our goal is to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: http://groupware.les.inf.puc-rio.br/har (see the section on the Weight Lifting Exercise Dataset).

The goal of this project is to predict the manner in which they did the exercise. This is the "classe" variable in the training set. Our results show the Random Forest model gives the best performance.

## Data Source
The training data for this project are available here: [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv]

The test data are available here: [https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv]

The data for this project come from this source: [http://groupware.les.inf.puc-rio.br/har].

##Data Processing
We load both the training and testing datasets to R and replace all missing values with NA. We found lots of columns whose values are all missing. So we remove these columns. Also the first seven columns appears irrelevant to the measures we are interested and so we remove them as well.

```{r}
training <- read.csv("pml-training.csv", na.strings=c("NA","#DIV/0!", ""))
testing <- read.csv("pml-testing.csv", na.strings=c("NA","#DIV/0!", ""))

dim(training)
dim(testing)

# Remove columns with all missing values
training<-training[,colSums(is.na(training)) == 0]
testing <-testing[,colSums(is.na(testing)) == 0]

# Remove irrelevant variables
training <-training[,-c(1:7)]
testing <-testing[,-c(1:7)]

dim(training)
dim(testing)
```

##Out-of-sample Error and Cross Validation
The training data set contains 53 variables and 19622 observations.
The testing data set contains 53 variables and 20 observations.

Normally the error rate against the training data is smaller than the out-of-sample error as the model tends to overfit the training data. In order to accurately estimate the out-of-sample error, we use a simple cross validation based on the traning dataset (the sample). The training dataset is partionned into 2 sets: myTrain (75%) and myTest (25%). This will be performed using random subsampling without replacement.

As it involves random sampling, we set a seed for reproducibility.

```{r}
library(caret)
set.seed(6188)
inTrain <- createDataPartition(y=training$classe, p=0.75, list=FALSE)
myTrain <- training[inTrain, ]
myTest <- training[-inTrain, ]

dim(myTrain)
dim(myTest)
```

##Classification Model Selection
First, we use Decision Tree as the classification model.

```{r}
#Decision Tree
library(rpart)
dt.fit <- rpart(classe ~. , data=myTrain, method="class")
dt.pred <- predict(dt.fit, newdata=myTest, type="class")
confusionMatrix(dt.pred, myTest$classe)
```

We then use the Random Forest model for the classification. In most cases, random forest should do better than decision trees.

```{r}
#Random Forest
library(randomForest)
rf.fit <- randomForest(classe ~. , data=myTrain, method="class")
rf.pred <- predict(rf.fit, newdata=myTest, type="class")
confusionMatrix(rf.pred, myTest$classe)
```

##Results and Conclusion
As expected, Random Forest algorithm performed better than Decision Trees.

Accuracy for Random Forest model was 0.996 (95% CI: (0.994, 0.998)) compared to 0.742 (95% CI: (0.73, 0.755)) for Decision Tree model. The random Forest model is choosen. The accuracy of the model is 0.9957. The expected out-of-sample error is estimated at 0.004, or 0.4%. Our Test data set comprises 20 cases. With an accuracy above 99% on our cross-validation data, we can expect that very few, or none, of the test samples will be missclassified.

We apply the Random Forest model to the testing set and the results are as follows:

```{r}
#Random Forest
rf.pred.testing <- predict(rf.fit, newdata=testing, type="class")
rf.pred.testing
```

##References
[1] Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.

